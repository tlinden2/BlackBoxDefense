"""
Author: Moustafa Alzantot (malzantot@ucla.edu)

"""

import numpy as np
import tensorflow as tf
from speech_commands import label_wav
import os, sys
import csv

import math
import models
import freeze

flags = tf.flags
flags.DEFINE_string('output_dir', '', 'output data directory')
flags.DEFINE_string('labels_file', '', 'Labels file.')
flags.DEFINE_string('graph_file', '', '')
flags.DEFINE_string('output_file', 'realdata_eval_output.csv', 'CSV file of evaluation results')
FLAGS = flags.FLAGS

def load_graph(filename):
    with tf.gfile.FastGFile(filename, 'rb') as f:
        graph_def = tf.GraphDef()
        graph_def.ParseFromString(f.read())
        tf.import_graph_def(graph_def, name='')

def load_labels(filename):
    return [line.rstrip() for line in tf.gfile.FastGFile(filename)]


def load_audiofile(filename):
    with open(filename, 'rb') as fh:
        return fh.read()

def add_random_noise(sess,w):
    mean = 0.0
    stddev = reduce_std(w)*rand_factor
    variables_shape = tf.shape(w)
    noise = tf.random_normal(
        variables_shape,
        mean=mean,
        stddev=stddev,
        dtype=tf.float32,
    )
    w_noise = tf.add(w,noise)
    sess.run(tf.assign(w, w_noise))
    return noise

def assign_to_var(w):
    variables_shape = tf.shape(w)
    w_ori = tf.Variable(tf.zeros(variables_shape,tf.float32))
    sess.run(tf.assign(w_ori, w))
    return w_ori


def recover_noise(sess, w, w_ori):
    sess.run(tf.assign(w, w_ori))
    return 

def reduce_std(x, axis=None, keepdims=False):
    """Standard deviation of a tensor, alongside the specified axis.

    # Arguments
        x: A tensor or variable.
        axis: An integer, the axis to compute the standard deviation.
        keepdims: A boolean, whether to keep the dimensions or not.
            If `keepdims` is `False`, the rank of the tensor is reduced
            by 1. If `keepdims` is `True`,
            the reduced dimension is retained with length 1.

    # Returns
        A tensor with the standard deviation of elements of `x`.
    """
    return tf.sqrt(reduce_var(x, axis=axis, keepdims=keepdims))

def reduce_var(x, axis=None, keepdims=False):
    """Variance of a tensor, alongside the specified axis.

    # Arguments
        x: A tensor or variable.
        axis: An integer, the axis to compute the variance.
        keepdims: A boolean, whether to keep the dimensions or not.
            If `keepdims` is `False`, the rank of the tensor is reduced
            by 1. If `keepdims` is `True`,
            the reduced dimension is retained with length 1.

    # Returns
        A tensor with the variance of elements of `x`.
    """
    m = tf.reduce_mean(x, axis=axis, keep_dims=True)
    devs_squared = tf.square(x - m)
    return tf.reduce_mean(devs_squared, axis=axis, keep_dims=keepdims)

if __name__ == '__main__':
    # JL: default values:
    wanted_words = 'yes,no,up,down,left,right,on,off,stop,go'
    sample_rate = 16000
    clip_duration_ms = 1000
    clip_stride_ms = 30
    window_size_ms = 30.0
    window_stride_ms = 10.0
    dct_coefficient_count = 40
    model_architecture = 'conv'
    rand_factor = 0.01
    num_md = 1 # number of randomized model to ensamble


    output_dir = FLAGS.output_dir
    labels_file = FLAGS.labels_file
    graph_file = FLAGS.graph_file
    output_file = FLAGS.output_file
    labels = load_labels(labels_file)
    n_labels = len(labels)
    result_mat = np.zeros((1, n_labels))
    input_node_name = 'wav_data:0'
    output_node_name = 'labels_softmax:0'
    # load_graph(graph_file)
    
    ## Header of output file
    output_fh = open(output_file, 'w')
    fieldnames = ['filename', 'original', 'predicted']
    for label in labels:
        fieldnames.append(label)
    csv_writer = csv.DictWriter(output_fh, fieldnames=fieldnames)
    print(fieldnames)
    csv_writer.writeheader()
    with tf.Session() as sess:
        # JL: use tf.InteractiveSession() and create interence graph here from checkpoint file
        freeze.create_inference_graph(wanted_words, sample_rate,
                    clip_duration_ms, clip_stride_ms,
                    window_size_ms, window_stride_ms,
                    dct_coefficient_count, model_architecture)
        models.load_variables_from_checkpoint(sess, graph_file) # load model from check point
        v_ori_1 = sess.graph.get_tensor_by_name('Variable:0') # get first layer to modify
        v_ori_2 = sess.graph.get_tensor_by_name('Variable_2:0') # get second layer to modify
        v_ori_cpy_1 = assign_to_var(v_ori_1)
        v_ori_cpy_2 = assign_to_var(v_ori_2)
        # get originial variables
        # assign new values in the loop
        output_node = sess.graph.get_tensor_by_name(output_node_name) 
        for label_idx, label_name in enumerate(labels):
            case_dir = format("%s/%s" %(output_dir, label_name))
            if os.path.exists(case_dir):
                wav_files =[format('%s/%s' %(case_dir, f)) for f in os.listdir(case_dir) if f.endswith('.wav')]
                cnt_trial = 1;
                for wav_filename in wav_files:


                    wav_data = load_audiofile(wav_filename)
                    # preds = sess.run(output_node, feed_dict = {
                    #             input_node_name: wav_data
                    #     })


                    # JL: print variables, 2 layers like to be variable:0, ansd variable_2:0

                    preds_stat = [0]*len(labels)

                    for cnt_md in range(0, num_md):
                        noise_1 = add_random_noise(sess,v_ori_1)
                        noise_2 = add_random_noise(sess,v_ori_2)

                        preds = sess.run(output_node, feed_dict = {
                                input_node_name: wav_data
                        })

                        recover_noise(sess, v_ori_1, v_ori_cpy_1)
                        recover_noise(sess, v_ori_2, v_ori_cpy_2)
                        preds_stat[np.argmax(preds[0])] += 1

                    wav_pred = preds_stat.index(max(preds_stat))  
                    #wav_pred = np.argmax(preds[0])
                    # print(wav_pred)
                    # print(label_idx)
                    print(cnt_trial)
                    if wav_pred == label_idx:
                        result_mat[0][wav_pred] += 1
                    row_dict = dict()
                    row_dict['filename'] = wav_filename
                    row_dict['original'] = label_name
                    row_dict['predicted'] = labels[wav_pred]
                    for i in range(preds[0].shape[0]):
                        row_dict[labels[i]] = preds[0][i]
                    csv_writer.writerow(row_dict)                    
                    cnt_trial += 1
                    if cnt_trial == 11:
                        break
        
        print(result_mat)
        print(np.sum(result_mat))

                        

